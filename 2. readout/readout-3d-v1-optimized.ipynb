{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sys\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "# Add the parent directory of simpleparameterisation to the sys.path list\n",
    "sys.path.append('../')\n",
    "\n",
    "# Now you can import simpleparameterisation from the new location\n",
    "import TPCevt as TPC\n",
    "\n",
    "det = TPC.Detector(\"Simple TPC with Atmospheric Ar (default values)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Parameter\n",
    "pitch_x = 0.1\n",
    "pitch_y = 0.1\n",
    "pitch_z = 0.1\n",
    "std = det.PSFstd = 1\n",
    "thresh = 1e-20\n",
    "grid_size = 500\n",
    "rv = multivariate_normal([0,0,0], np.diag([std, std, std]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Definition\n",
    "def getDistribution(grid_size, offset):\n",
    "    x, y, z = np.mgrid[-grid_size*pitch_x:(grid_size+1)*pitch_x:pitch_x,\n",
    "            -grid_size*pitch_y:(grid_size+1)*pitch_y:pitch_y,\n",
    "            -grid_size*pitch_z:(grid_size+1)*pitch_z:pitch_z,\n",
    "            ]\n",
    "    offset_x, offset_y, offset_z = offset\n",
    "\n",
    "    # gain = np.random.exponential(scale=det.gain_mean)\n",
    "    gain = 1\n",
    "    # top_right = np.stack((np.array([x+pitch_x/2-offset_x, y+pitch_y/2-offset_y])), axis=-1)\n",
    "    # bottom = np.stack((np.array([x+pitch_x/2-offset_x, y-pitch_y/2-offset_y])), axis=-1)\n",
    "    # left = np.stack((np.array([x-pitch_x/2-offset_x, y+pitch_y/2-offset_y])), axis=-1)\n",
    "    # bottom_left = np.stack((np.array([x-pitch_x/2-offset_x, y-pitch_y/2-offset_y])), axis=-1)\n",
    "    val = rv.pdf(np.stack((x, y, z), axis = -1))*pitch_x*pitch_y*pitch_z*gain\n",
    "    # gain=1 #not considering gain effect for temporary\n",
    "\n",
    "    # val_cdf = (rv.cdf(top_right) - rv.cdf(bottom) - rv.cdf(left) + rv.cdf(bottom_left))*gain\n",
    "\n",
    "    # plt.figure()\n",
    "    # plt.title('Val CDF')\n",
    "    # plt.scatter(x, y, c=val_cdf)\n",
    "    # plt.xlim(-5, 5)\n",
    "    # plt.ylim(-5, 5)\n",
    "    # plt.colorbar()\n",
    "    return x, y, z, val\n",
    "\n",
    "def applyThreshold(x_1, y_1, z_1, readout_1, thresh):\n",
    "    mask_1 = readout_1 >= thresh\n",
    "    x_1_filtered = x_1[mask_1].flatten()\n",
    "    y_1_filtered = y_1[mask_1].flatten()\n",
    "    z_1_filtered = z_1[mask_1].flatten()\n",
    "    \n",
    "    readout_1_filtered = readout_1[mask_1]\n",
    "    return x_1_filtered, y_1_filtered, z_1_filtered, readout_1_filtered\n",
    "\n",
    "\n",
    "def filterCoord(x, y, z, val, minvals, maxvals):\n",
    "    # Convert input lists to NumPy arrays\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    z = np.array(z)\n",
    "    val = np.array(val)\n",
    "\n",
    "    # Define masks for filtering\n",
    "    x_mask = (minvals[0] <= x) & (x <= maxvals[0])\n",
    "    y_mask = (minvals[1] <= y) & (y <= maxvals[1])\n",
    "    z_mask = (minvals[2] <= z)\n",
    "\n",
    "    # Combine the masks to get the final filtering mask\n",
    "    final_mask = x_mask & y_mask & z_mask\n",
    "\n",
    "    # Use the filtering mask to get the filtered arrays\n",
    "    filtered_x = x[final_mask]\n",
    "    filtered_y = y[final_mask]\n",
    "    filtered_z = z[final_mask]\n",
    "    filtered_val = val[final_mask]\n",
    "\n",
    "    return [filtered_x, filtered_y, filtered_z, filtered_val]\n",
    "\n",
    "\n",
    "def filterCoord_vect(x, y, z, val, minvals, maxvals):\n",
    "    # Convert input lists to NumPy arrays\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    z = np.array(z)\n",
    "    val = np.array(val)\n",
    "\n",
    "    # Define masks for filtering\n",
    "    x_mask = (minvals[0] <= x) & (x <= maxvals[0])\n",
    "    y_mask = (minvals[1] <= y) & (y <= maxvals[1])\n",
    "    z_mask = (minvals[2] <= z)\n",
    "\n",
    "    # Combine the masks to get the final filtering mask\n",
    "    final_mask = x_mask & y_mask & z_mask\n",
    "\n",
    "    # Use the filtering mask to get the filtered arrays\n",
    "    filtered_x = x[final_mask]\n",
    "    filtered_y = y[final_mask]\n",
    "    filtered_z = z[final_mask]\n",
    "    filtered_val = val[final_mask]\n",
    "\n",
    "    return [filtered_x, filtered_y, filtered_z, filtered_val]\n",
    "\n",
    "\n",
    "def getGridProps(coord, delta):\n",
    "    index = int((coord + delta / 2) // delta)\n",
    "    offset = coord - index*delta\n",
    "    return index, offset\n",
    "\n",
    "def count_decimal_places(number):\n",
    "    if \".\" not in str(number):\n",
    "        return 0\n",
    "    return len(str(number).split(\".\")[1])\n",
    "\n",
    "def ReadoutGain(DriftedEvt):\n",
    "    DriftedEvtGrid = np.stack(DriftedEvt, axis=-1)\n",
    "    minvals = np.array([DriftedEvtGrid[0].min(), DriftedEvtGrid[1].min(), DriftedEvtGrid[2].min()])\n",
    "    maxvals = np.array([DriftedEvtGrid[0].max(), DriftedEvtGrid[1].max(), DriftedEvtGrid[2].max()])\n",
    "    print(minvals, maxvals)\n",
    "    CombinedEvt = {}\n",
    "    comma_num_x = count_decimal_places(pitch_x)\n",
    "    comma_num_y = count_decimal_places(pitch_y)\n",
    "    comma_num_z = count_decimal_places(pitch_z)\n",
    "\n",
    "    def combineData(x, y, z, val):\n",
    "        for i in range(len(x)):\n",
    "            key = (np.around(x[i], comma_num_x), np.around(y[i], comma_num_y), np.around(z[i], comma_num_z))\n",
    "            if key in CombinedEvt:\n",
    "                # print('initial', CombinedEvt[key])\n",
    "                CombinedEvt[key] += val[i]\n",
    "                # print('final', CombinedEvt[key])\n",
    "            else:\n",
    "                CombinedEvt[key] = val[i]\n",
    "\n",
    "    for i in range(len(DriftedEvt)):\n",
    "        coord = DriftedEvt[i]\n",
    "        (index_x, offset_x) = getGridProps(coord[0], pitch_x)\n",
    "        # print('index_x: ', index_x,', offset_x: ',  offset_x)\n",
    "\n",
    "        (index_y, offset_y) = getGridProps(coord[1], pitch_y)\n",
    "        # print('index_y: ', index_y,', offset_y: ',  offset_y)\n",
    "\n",
    "        (index_z, offset_z) = getGridProps(coord[2], pitch_z)\n",
    "        # print('index_y: ', index_y,', offset_y: ',  offset_y)\n",
    "\n",
    "        x_1, y_1, z_1, readout_1 = getDistribution(grid_size, [offset_x, offset_y, offset_z])\n",
    "\n",
    "        x_1_filtered, y_1_filtered, z_1_filtered, readout_1_filtered = applyThreshold(x_1, y_1, z_1, readout_1, thresh)\n",
    "        \n",
    "        x_1_filtered += index_x*pitch_x\n",
    "        y_1_filtered += index_y*pitch_y\n",
    "        z_1_filtered += index_z*pitch_z\n",
    "        \n",
    "        # plt.figure()\n",
    "        # plt.title('DriftedEvt item-')\n",
    "        # plt.scatter(x_1_filtered, y_1_filtered, c=readout_1_filtered)\n",
    "        # plt.colorbar()\n",
    "        \n",
    "        combineData(x_1_filtered, y_1_filtered, z_1_filtered, readout_1_filtered)\n",
    "        x_comb, y_comb, z_comb = zip(*CombinedEvt.keys())\n",
    "        \n",
    "    val_comb = list(CombinedEvt.values())\n",
    "    # print('time vectorization')\n",
    "    # %timeit filtered_coord_vect = filterCoord_vect(x_comb, y_comb, z_comb, val_comb, minvals, maxvals)\n",
    "    # print('time loop')\n",
    "    # %timeit filtered_coord = filterCoord(x_comb, y_comb, z_comb, val_comb, minvals, maxvals)\n",
    "    \n",
    "    filtered_coord = filterCoord(x_comb, y_comb, z_comb, val_comb, minvals, maxvals)\n",
    "    \n",
    "    return filtered_coord\n",
    "\n",
    "def plotReadout(ReadoutEvt):\n",
    "    plt.figure(1)\n",
    "    projectxy = pd.DataFrame(ReadoutEvt.groupby(['x','y'])['Nel'].sum()).reset_index()\n",
    "    plt.scatter(projectxy.x,projectxy.y, c=projectxy.Nel, s=((projectxy.Nel/np.max(projectxy.Nel))**0.5)*chart_scaling)\n",
    "    plt.colorbar()\n",
    "    plt.title(\" X-Y Chart \")\n",
    "    # plt.savefig('export/chart_X-Y.png')\n",
    "\n",
    "    plt.figure(2)\n",
    "    projectxdt = pd.DataFrame(ReadoutEvt.groupby(['x','dt'])['Nel'].sum()).reset_index()\n",
    "    plt.scatter(projectxdt.x,projectxdt.dt, c=projectxdt.Nel, s=((projectxdt.Nel/np.max(projectxdt.Nel))**0.5)*chart_scaling)\n",
    "    plt.colorbar()\n",
    "    plt.title(\" X-Z Chart \")\n",
    "    # plt.savefig('export/chart_X-dT.png')\n",
    "\n",
    "    plt.figure(3)\n",
    "    projectydt = pd.DataFrame(ReadoutEvt.groupby(['y','dt'])['Nel'].sum()).reset_index()\n",
    "    plt.scatter(projectydt.y,projectydt.dt, c=projectydt.Nel, s=((projectydt.Nel/np.max(projectydt.Nel))**0.5)*chart_scaling)\n",
    "    plt.colorbar()\n",
    "    plt.title(\" Y-Z Chart \")\n",
    "    # plt.savefig('export/chart_Y-dT.png')\n",
    "    \n",
    "    fig = plt.figure(4)\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    scatter = ax.scatter(ReadoutEvt['x'], ReadoutEvt['y'], ReadoutEvt['dt'], c=ReadoutEvt['Nel'], cmap='viridis', marker='o')\n",
    "    cbar = plt.colorbar(scatter)\n",
    "    plt.title(\" X-Y-Z Chart\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "frt-development",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
